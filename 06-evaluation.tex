\section{Evaluation}\label{sec:evaluation}
The evaluation focuses on computations that are expected to profit from parallelization, e.g. compute-intensive tasks or tasks over a large set of data. However, using the presented runtime system may also be beneficial for long-running, but not parallelized computations that otherwise would block the main thread and result in a degraded user experience. The evaluation compares the presented work with the alternatives introduced in \cref{sec:related-work} concerning applicability and performance to the following set of problems:

\begin{itemize}
	\item[$\bullet$] Knight Tour: Computes the number of open tours from a given start field. This problem has a low memory but very high computational needs.
	\item[$\bullet$] Mandelbrot $10'000 \times 10'000$: Computation of a Mandelbrot for a given image size. This problem requires a large amount of memory compared to the computational time needed.
	\item[$\bullet$] Risk Profiling: The risk profiling uses a Monte Carlo simulation to create forecasts for the customer's asset development over a period of 15 years for various investment strategies and assuming different states of the economic. The forecast is used to illustrate how a chosen investment strategy effects the development of his assets and therefore, planned investments --- e.g. buying a house after ten years. This problem is an instance of a real-world problem~\cite{Kwsoft2016}.
\end{itemize}

The versions of the evaluated runtime systems are shown in \cref{tab:runtime-system-version}.

\begin{table}
	\centering
	\begin{tabular}{p{0.6\linewidth} l}
		\toprule
		Runtime System & Version \\ \midrule
		Parallel.es & 0.1.17 \\
		Hamsters.js & 3.9.0\footnote{The version used is based on 3.9.0 but contains a fix for input data that is not a typed array (\url{https://github.com/austinksmith/Hamsters.js/issues/16}).} \\
		Parallel.js & 0.2.x\footnote{Latest version from master as mentioned in \cref{sec:related-work}.} \\
		Threads.js & 0.7.2 \\ \bottomrule
	\end{tabular}
	\caption{Versions of Evaluated Runtime Systems}
	\label{tab:runtime-system-version}
\end{table}


\subsection{Applicability}
The applicability is evaluated by comparing the Mandelbrot implementations. The reference implementation for the evaluation is the sequential, lodash~\cite{lodash} based implementation of the Mandelbrot that has been introduced in \cref{sec:programming-model} and is shown in \cref{fig:mandelbrot-sync}. The implementations for the specific runtime systems highlight differences to the reference implementations in gray. The implementation to compute a single pixel is omitted for brevity since it is identical for all evaluated runtime system. The preliminary focus of the evaluation is how seamless the integration into existing code is and the type-safety of the API. Some of the results might be subjective and represent the opinion of the author. 

\paragraph{Parallel.es}
The Parallel.es based implementation of the Mandelbrot from \cref{sec:programming-model} and shown in  \cref{code:mandelbrot-parallel.es} is almost identical to the sequential implementation. The implementation does not require any adjustment of the sequential implementation except the adoption to the Parallel.es API. Simply because the task function can reference read-only variables and functions from its outer scope allowing a seamless integration of parallel task into existing applications. However, this liberty comes at the cost of requiring a potentially additional build step to transpile the program code. The author believes that the benefits of a seamless integration outweigh the additional complexity in the build process. Especially because transpiling of source code --- mostly using Babel~\cite{babel} --- is very common in the JavaScript community. 

\paragraph{Parallel.js}
\Cref{fig:mandelbrot-paralleljs} shows the Mandelbrot implementation using the reactive API of Parallel.js. It differs only slightly from the sequential implementation. A parallel task is created using the \javascriptinline/Parallel/ constructor (line \ref{code:paralleljs-definition}). The first constructor argument is the data to process, the second --- optional --- argument is an options object affecting the task execution. The value of the options-object's \javascriptinline/env/ property is exposed as \javascriptinline/global.env/ in the background thread (line \ref{code:paralleljs-global}). The task function passed to the \javascriptinline/map/ operation (line \ref{code:paralleljs-map}) is called for every element in the input array and produces the elements in the output array.

\begin{listing}
	\begin{javascriptcode*}{highlightlines={9, 22-29}}
const imageWidth = 10000;
const imageHeight = 10000;

function computePixel(x, y) {
	// ...
	return n;
}

function computeMandelbrotLine(y, imageWidth) {
	const arraySize = imageWidth * 4;
	const line = new Uint8ClampedArray(arraySize);
	
	for (let x = 0; x < imageWidth; ++x) {
		line[x * 4] = computePixel(x, y);
	}
	
	return line;
}

const lines = _.range(imageHeight);

new Parallel(lines, {env: { imageWidth } }) |$\label{code:paralleljs-definition}$|
	.require(computeMandelbrotLine) |$\label{code:paralleljs-require}$|
	.require(computePixel)
	.map(function (line) { |$\label{code:paralleljs-map}$|
		const width = global.env.imageWidth;|$\label{code:paralleljs-global}$|
		return computeMandelbrotLine(line, width));
	})
	.then(result => console.log(result));
\end{javascriptcode*}

\caption{Mandelbrot Implementation using Parallel.js}
\label{fig:mandelbrot-paralleljs}
\end{listing}

Parallel.js requires functions called from inside of a task function to be made explicitly available by using the \javascriptinline/require/ method (line \ref{code:paralleljs-require}). Additionally, the variable \javascriptinline/imageWidth/ can not be referenced by the task function (and the \javascriptinline/computeMandelbrot/ function). Instead, the value needs to be explicitly passed to the background thread by storing it in the \javascriptinline/env/ property of the options-object (line \ref{code:paralleljs-definition}) and retrieving it in the task function by using \javascriptinline/global.env/ (line \ref{code:paralleljs-global}).


The use of the undeclared variable \javascriptinline/global/ (line \ref{code:paralleljs-global}) to expose additional data in the task function is problematic since it breaks static scoping and requires additional care in typed languages. Typed languages require the variable \javascriptinline/global/ to be declared. It can either be declared in every module it is used or globally in a declaration file. In both cases, no specific type can be annotated for the environment property since its type depends upon the actual problem. Therefore, type checking needs to be disabled for the environment property by annotating a special opt-out type like \javascriptinline/any/ in TypeScript~\cite{typescript}. However, declaring the variable has the undesired side effect that the type checker no longer detects illegal usages of the variable outside of a task function in which case the variable is truly undeclared. The \javascriptinline/global/ variable also hinders code reuse because the global variable is undeclared if a task function is called from the main thread.

The implementation of the risk profiling problem in Parallel.js requires some tricks to be performant. The issue is that Parallel.js provides no mean to store the Monte Carlo simulation results across the invocations of the task function other than saving it in the global context of the background thread. Storing the simulation result in the global context is unaesthetic but can not introduce memory leaks since Parallel.js terminates the background threads when the operation has completed. However, an explicit API from Parallel.js would be favored that also remains functional if Parallel.js is using thread pools in the future.

To sum up, the API has the disadvantage not to be type-safe and does not allow to store data across task function invocations. Furthermore, variables and functions used in the task function need to be explicitly made available, resulting in a clear break of the programming style. The API of Parallel.js offers the powerful feature to include additional functions in a task without the need for static code transpilation --- as it is by Parallel.es --- by using the \javascriptinline/require/ function (line \ref{code:paralleljs-require}).

\paragraph{Threads.js}
\Cref{fig:mandelbrot-threadsjs} shows the Threads.js based Mandelbrot implementation. Threads.js can be used with or without thread pools. A thread pool needs to be created manually if one is desired (line \ref{code:threadsjs-pool}). The task function is specified by using the \javascriptinline/pool.run/ method (line \ref{code:threadsjs-worker}). A new task for this function is created by invoking the \javascriptinline/send/ method (line \ref{code:threadsjs-messaging}) where the passed arguments are used to invoke the task function in the background thread. The result of a single task can be retrieved by registering the \javascriptinline/done/ handler (line \ref{code:threadsjs-task-completion}) that in this example is used to manually join the sub-results of the tasks. The thread pool offers the \javascriptinline/finished/ event (line \ref{code:threadsjs-done}) that is triggered when all tasks of this pool have been completed\footnote{The finished event cannot be used if other tasks are executed on the same thread pool.}.

\begin{listing}
	\begin{javascriptcode*}{highlightlines={5, 17, 20-21, 27-28, 31}}
const imageWidth = 10000;
const imageHeight = 10000;

function computeMandelbrotLine({ y, width}, done) {
	function computePixel(x, y) {|$\label{code:threadsjs-compute-pixel}$|
		// ...
		return n;
	}
	
	const arraySize = width * 4;
	const line = new Uint8ClampedArray(arraySize);

	for (let x = 0; x < width; ++x) {
		line[x * 4] = computePixel(x, y);
	}

	done.transfer(line, [line.buffer]);
}

const pool = new Pool(); |$\label{code:threadsjs-pool}$|
pool.run(computeMandelbrotLine); |$\label{code:threadsjs-worker}$|

const lines = _.range(imageHeight);
const result = new Array(imageHeight);
for (const y of lines) {
	pool
		.send({ y, imageWidth }) |$\label{code:threadsjs-messaging}$|
		.on("done", line => result[y] = line);|$\label{code:threadsjs-task-completion}$|
}

pool.on("finished", () => console.log(result)); |$\label{code:threadsjs-done}$|
\end{javascriptcode*}
\caption{Mandelbrot Implementation using threads.js}
\label{fig:mandelbrot-threadsjs}
\end{listing}


The Threads.js API offers a clean, flexible, messaging-based API to run single tasks in background threads but does not provide a higher-level abstraction for common operations. This lack of a higher-level API complicates the migration of existing code since the programmer needs to partition the work into different tasks, join the sub-results, and is responsible for managing the lifetime of the thread pool. Neither provides the API a mechanism to expose a function from the same module to the task function. Therefore, the \javascriptinline/computePixel/ function (line \ref{code:threadsjs-compute-pixel}) has to be nested inside of the \javascriptinline/computeMandelbrotLine/ function. This missing feature restricts the programmer in his options to structure the code. Moreover, the API is not type-safe since the \javascriptinline/run/ method does not return a new instance; it instead changes the existing one. A new instance is required to reflect that the arguments of the \javascriptinline/send/ method have to be subtypes of the task function's parameters which is specified using the \javascriptinline/run/ method. 

The implementation of the risk profiling problem in Threads.js requires to store the Monte Carlo simulation results in the global context of the background thread to be performant for the same reason as for Parallel.js. However, this misuse of the global context introduces memory leaks if a shared thread pool is used. It would, therefore, be preferred to have an explicit API provided by Threads.js to store data across task function invocations.

To sum up. The API of Threads.js is simple in use but commonly used features like the joining of the sub-results are missing. The messaging-based programming model results in a clear break of the code style. Moreover, the API is not type-safe, making it a nonideal choice for projects using typed language.

\paragraph{Hamsters.js}
\Cref{fig:mandelbrot-hamsterjs} shows the Mandelbrot implementation using Hamsters.js. A task is started using the \javascriptinline/hamsters.run/ method (line \ref{code:hamsterjs-start}). The passed arguments have the following semantic:

\begin{enumerate}
	\item An object that is passed to the task function. The special property \javascriptinline/array/ defines the input data. The object is exposed by the \javascriptinline/params/ variable (linel \ref{code:hamstersjs-params} and \ref{code:hamstersjs-params-two}) in the task function.
	\item The task function to execute in a background thread.
	\item The callback function that is invoked when the operation has completed.
	\item The number of tasks to create at most --- into how many tasks should the input data be partitioned. 
	\item Defines if the sub-results of the tasks are automatically joined (\javascriptinline/true/) into the end-result.
\end{enumerate}

Hamsters.js automatically splits the input data into sub-arrays where each sub-array is processed by a single task. However, iterating over the elements of the sub-array is left to the task function (line \ref{code:hamsterjs-iterate}). The result of the task function has to be written into the \javascriptinline/rtn.data/ array (line \ref{code:hamsterjs-result}) that is provided by Hamsters.js. 

\begin{listing}
\begin{javascriptcode*}{highlightlines={5, 10-11, 15, 22, 26-34}}
const imageWidth = 10000;
const imageHeight = 10000;

function computeMandelbrotLine () {
	function computePixel(x, y) {|$\label{code:hamstersjs-compute-pixel}$|
		// ...
		return n;
	}

	const options = params.options; |$\label{code:hamstersjs-params}$|
	const input = params.array; |$\label{code:hamstersjs-params-two}$|

	const arraySize = options.imageWidth * 4;

	for (let i = 0; i < input.length; ++i) {|$\label{code:hamsterjs-iterate}$|
		const y = input[i];
		const line = new Uint8ClampedArray(arraySize);
		
		for (let x = 0; x < width; ++x) {
			line[x * 4] = computePixel(x, y);
		}
		rtn.data.push(line); |$\label{code:hamsterjs-result}$|
	}
}

hamsters.run( |$\label{code:hamsterjs-start}$|
	params: {
		array: _.range(options.imageHeight),
		options
	},  
	computeMandelbrotLine, 
	result => console.log(result), 
	hamsters.maxThreads, 
	true);
\end{javascriptcode*}
\caption{Mandelbrot Implementation using Hamsters.js}
\label{fig:mandelbrot-hamsterjs}
\end{listing}

The API of Hamsters.js is a mixture of a low- and high-level API: On one hand, it offers only a single \javascriptinline/run/ method, on the other, advanced features like work partitioning, result joining, and result caching are provided. The author believes that exposing all these features in a single method makes the API hard to use because it is hard to remember the correct ordering and semantic of the arguments. Even though Hamsters.js offers a high-level API, still most of the work is left to the programmer like iterating over the input array elements. Like Threads.js, other functions defined in the same module can not be exposed to the task function requiring to nest the \javascriptinline/computePixel/ function (line \ref{code:hamstersjs-compute-pixel}) inside of the \javascriptinline/computeMandelbrotLine/ function restricting the programmer in its liberty to structure the code as he prefers and resulting in a clear break of the code style. The API further has the disadvantage not to be type-safe because of the undeclared \javascriptinline/params/ (line \ref{code:hamstersjs-params}) and \javascriptinline/rtn/ (line \ref{code:hamsterjs-result}) variables in the task function. These variables also hinder code reuse because they are undeclared if the function is not invoked as a task function.

\subsection{Performance Comparison}
The benchmark results from \cref{fig:runtime-performance} show the absolute time needed by each implementation and a percentage indicating the fraction of the sequential runtime. The test setup uses a Windows 10 computer with a 4-Core, 2.5 GHz Xeon E5-2609v2 processor. The benchmark has been performed on all major browsers. Some of the results differ significantly from one another upon the used browser. These discrepancies are caused by the browser specific JIT-optimizations. Microsoft Edge shows the most notable discrepancies since the performance of parallel computations drops significantly if the runtime system uses \javascriptinline/new Function/ or \javascriptinline/eval/ to create dynamic function instances --- which is the case for Hamsters.js and Threads.js. This observation has been reported and is confirmed by Microsoft~\cite{newFunctionWebWorkerEdge}. The following section describes the benchmark results measured using Firefox v.50. These results are used because they do not contain outliners caused by the browser's JIT-Optimizations as it is the case for other browsers.

\begin{figure*}
	\input{Firefox-50.0}	
	\caption{Runtime Performance of Parallelization Problems Relative to Sequential Execution}
	\label{fig:runtime-performance}
\end{figure*}


\paragraph{Knight Tour} The time needed to solve the knight tour problem is mainly determined by the available computational resources. The calculation is parallelized by computing different start-field sequences in each task and summarizing the number of found tours at the end. 

Parallel.js creates new tasks for accumulating the sub-results of start-field sequences computed by two tasks and executes them on designated background threads. The spawning of new background threads for accumulating the sub-results cause a significant overhead for the smaller $5\times5$ board. However, the impact is no longer visible for the larger board.

The results of Firefox do not indicate any advantage of using a thread pool over spawning new background threads for every task. It seems that creating background threads in Firefox is very inexpensive. However, the benchmarking results of Google Chrome v. 54 shown in \cref{fig:runtime-performance-chrome} give evidence that a thread pool might be advantageous for very short running tasks. Thus, Hamsters.js and Parallel.es achieve slightly better results than Parallel.js, which is not using a thread pool at all, and Threads.js, where each benchmark run creates a new thread pool\footnote{A new thread pool for each run is not strictly necessary for the knight tour problem. However, it is needed to store the simulation result of the risk profiling problem.}. 

\begin{figure}
	\centering
	\input{knight-tour-5x5Chrome-54.0.2840.99}
	\caption{Knight Tour 5x5 Runtime Performance using Chrome}
	\label{fig:runtime-performance-chrome}
\end{figure}

The test case of the $6\times6$ knight tour only shows significant differences for the Hamsters.js runtime system. This difference is rooted in the strategy used to split the start-field sequences into tasks. The number of background threads used by Hamsters.js is manually defined to the number of logical processors offered by the hardware because it does not determine the optimal number of background threads automatically. Hamsters.js splits the start-field sequences evenly onto the available background threads. However, some start-field sequences require more time to compute than others, resulting in unused computation resources when other tasks complete early. Parallel.js and Threads.js always use a task size of one to avoid this misfortune situation. Parallel.es also uses an even work splitting strategy but creates four-times as many tasks as background threads are available to better balance the workload in case of nonlinear problems. This strategy has shown to be a beneficial balance between having a large enough set of items to process by each task, to reduce the overhead for starting the tasks, while still leaving room to compensate for nonlinear problems. 

\paragraph{Mandelbrot}
The Mandelbrot problem is parallelized by computing a subset of the lines per task. The time needed to compute a single line depends upon the position of the line in the image --- it is a nonlinear problem. This nonlinearity is the reason why the Hamsters.js based implementation takes significantly longer. Its even distribution of the work onto the background threads results in tasks computing the center of the Mandelbrot taking longer than the ones at the top or bottom of the field. 

The better performance of Threads.js is rooted insofar that Threads.js supports transferables~\cite[Section 2.7.4]{w3cHtml5}. Transferables allow moving a memory range between threads instead of copying it. Hamsters.js also support transferables, however, only if the input and output are transferable objects what is not the case for the Mandelbrot implementation.

\paragraph{Risk Profiling}
The risk profiling implementation uses sim.js~\cite{simjs} as random number generator in the Monte Carlo simulation. Sim.js is used because the random generator can be initialized with a seed number what is needed to achieve reproducible forecasts. Hamsters.js is not part of this evaluation since it lacks support for importing functions from other modules and can therefore not use the sim.js library. 

The problem is parallelized by computing the outcome for a subset of investments in each task. However, this requires that each background thread runs the Monte Carlo simulation to calculate the outcome of the planned investment. Therefore, only a smaller speedup is achieved by parallelizing this problem because of the significant overhead to compute the Monte Carlo simulation.

Parallel.es requires more time for the computation because of the work splitting strategy used. Parallel.es distributes the investments evenly onto the background threads. However, computing the result of an investment is nonlinear; It depends on the year in which the investment takes place, the later, the more values have to be computed. This nonlinear computation time results in some tasks completing earlier than others leaving computation resources unused. Enforcing a task-size of one is not a solution for this problem as it leads to recomputing the Monte Carlo simulation for each investment reducing the performance even more. Parallel.js and Threads.js can only use a task-size of one as the thread pool is not reused and therefore, side effects in the background threads can be used to store the simulation outcome in a global variable. Using side effects is not desired if shared background threads from a thread pool are used as it creates potential memory leaks.

\paragraph{Recursive Tasks} 
None of the evaluated libraries allow modeling recursive problems like the Knight-Tour or Quicksort naturally. Recursive problems have the characteristic that the input data for the subproblems is computed in the same step as the problem is solved. The backtracking based Knight Tour algorithm starts with a field and creates branches for every possible move by recursively descending for each distinct subpath allowing to parallelize the problem by computing each path in a separate task. This strategy requires a runtime system allowing to start subtasks from inside a task. These created subtasks can be executed on any background thread to achieve a better work balance. The current implementation does not support this scenario and therefore, the main thread precomputes start-field sequences that are solved sequentially without further dividing into subtasks.


An efficient implementation to support recursive tasks requires a communication channel between all web workers to allow to start a subtask on another, idle background thread without an additional roundtrip over the main thread. However, web workers only have a single communication channel between the thread that has started the web worker and the spawned web worker. Shared Workers~\cite[section 4.6.4]{w3cWebWorker} allow a worker to have multiple channels between various workers but are often unsupported by older browsers. Furthermore, the \enquote{run to completion} model of JavaScript can be problematic because a busy background thread does not process received messages until the current work has completed. Therefore, the background thread does not respond to received messages in a guaranteed timeframe.

Further research is required to determine how recursive tasks can be supported in an environment without shared memory and the \enquote{run to completion} model.

\subsection{Summary of Evaluation Results}
The evaluation of the performance shows that the result is mainly determined by the used work splitting strategy. Surprisingly, the overhead needed to run a task on a background thread is almost negligible. Therefore, a task size of one ---- as used by Parallel.js and Threads.js --- seems generally to be a better choice than processing too many elements in a single task. The latter is preliminary problematic if the problem itself is nonlinear in which case a smaller task size helps to balance the workload. The evenly splitting the work across the available number of background threads is the cause why Hamsters.js performs significantly worse than the other runtime systems for nonlinear problems. Parallel.es's approach of creating four times as many tasks as the hardware provides logical processors showed to be a good choice. 

The evaluated systems differ more significantly in their APIs. Some of the evaluated systems only offer a low-level API while other provide a high-level API as well. If one or the other is to be preferred is very subjective and principally dependend on the specific problem and the programmer's preferences. However, other properties are more objective: Hamsters.js impedes code reuse and is unsuitable if the task function depends upon libraries since it does not permit to expose additional functions, e.g. functions imported from libraries, to task functions. Parallel.es is the only valid option for projects using typed-languages because it is the only with a type-safe API. Threads.js supports transferables hat allow to move the result of a computation instead of copying it. This moving between threads results in better runtime performances for computations over large amounts of data like the Mandelbrot problem.


All the runtime systems have in common that they specify restrictions for task functions affecting the structuring of the code. This lack of freedom creates a clearly visible seam between parallel tasks and the rest of the application. Parallel.es reduces this seam to a minimum by transpiling the program code prior to execution allowing a far more complete set of JavaScript functions to be used as task functions.
